{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was used to process crop and houseplant images for a basic CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "# create list for healthy crop images\n",
    "healthycrop_arrays = []\n",
    "# define filepath for healthy crop images\n",
    "healthycrop_path = 'Data/crop_images/healthy/'\n",
    "\n",
    "# convert each image to normalized array and store\n",
    "count = 0\n",
    "for file in os.listdir(healthycrop_path):\n",
    "    if count < 500:\n",
    "        try:\n",
    "            # target_size automatically resizes each img on import\n",
    "            healthy = load_img(healthycrop_path + file, target_size=(256, 256))\n",
    "            healthy_arr = img_to_array(healthy) / 255\n",
    "            healthycrop_arrays.append(healthy_arr)\n",
    "        except:\n",
    "            print(f'Error for file: {file}')\n",
    "        count +=1\n",
    "\n",
    "print(f'{len(healthycrop_arrays)} pictures converted.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "# create list for healthy houseplant images\n",
    "healthyhouse_arrays = []\n",
    "# define filepath for healthy houseplant images\n",
    "healthyhouse_path = 'Data/houseplant_images/healthy/'\n",
    "\n",
    "# convert each image to normalized array and store\n",
    "count = 0\n",
    "for file in os.listdir(healthyhouse_path):\n",
    "    if count < 451:\n",
    "        try:\n",
    "            # target_size automatically resizes each img on import\n",
    "            healthy = load_img(healthyhouse_path + file, target_size=(256, 256))\n",
    "            healthy_arr = img_to_array(healthy) / 255\n",
    "            healthyhouse_arrays.append(healthy_arr)\n",
    "        except:\n",
    "            print(f'Error for file: {file}')\n",
    "        count +=1\n",
    "\n",
    "print(f'{len(healthyhouse_arrays)} pictures converted.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "# create list for diseased crop images\n",
    "diseasedcrop_arrays = []\n",
    "# define filepath for diseased crop images\n",
    "diseased_path = 'Data/crop_images/diseased/'\n",
    "\n",
    "# convert each image to normalized array and store\n",
    "count = 0\n",
    "for file in os.listdir(diseased_path):\n",
    "    if count < 500:\n",
    "        try:\n",
    "            # target_size automatically resizes each img on import\n",
    "            diseased = load_img(diseased_path + file, target_size=(256, 256))\n",
    "            diseased_arr = img_to_array(diseased) / 255\n",
    "            diseasedcrop_arrays.append(diseased_arr)\n",
    "        except:\n",
    "            print(f'Error for file: {file}')\n",
    "        count +=1\n",
    "\n",
    "print(f'{len(diseasedcrop_arrays)} pictures converted.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "# create list for wilted houseplant images\n",
    "wiltedhouse_arrays = []\n",
    "# define filepath for wilted houseplant images\n",
    "wilted_path = 'Data/houseplant_images/wilted/'\n",
    "\n",
    "# convert each image to normalized array and store\n",
    "count = 0\n",
    "for file in os.listdir(wilted_path):\n",
    "    if count < 451:\n",
    "        try:\n",
    "            # target_size automatically resizes each img on import\n",
    "            diseased = load_img(wilted_path + file, target_size=(256, 256))\n",
    "            diseased_arr = img_to_array(diseased) / 255\n",
    "            wiltedhouse_arrays.append(diseased_arr)\n",
    "        except:\n",
    "            print(f'Error for file: {file}')\n",
    "        count +=1\n",
    "\n",
    "print(f'{len(wiltedhouse_arrays)} pictures converted.')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1902, 256, 256, 3)\n",
      "y shape: (1902,)\n"
     ]
    }
   ],
   "source": [
    "# X should contain all converted images\n",
    "X = healthycrop_arrays + healthyhouse_arrays + diseasedcrop_arrays + wiltedhouse_arrays\n",
    "# convert to array and check shape\n",
    "X_arr = np.array(X)\n",
    "print(f'X shape: {X_arr.shape}')\n",
    "\n",
    "# 0 for healthy, 1 for not healthy\n",
    "y = [0] * 951 + [1] * 951\n",
    "# convert to array and check shape\n",
    "y = np.array(y)\n",
    "print(f'y shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1426 samples, validate on 476 samples\n",
      "Epoch 1/5\n",
      "1426/1426 [==============================] - 1154s 809ms/sample - loss: 1.7179 - accuracy: 0.5652 - val_loss: 0.6615 - val_accuracy: 0.5252\n",
      "Epoch 2/5\n",
      "1426/1426 [==============================] - 861s 604ms/sample - loss: 0.5898 - accuracy: 0.6781 - val_loss: 0.5623 - val_accuracy: 0.7353\n",
      "Epoch 3/5\n",
      "1426/1426 [==============================] - 577s 405ms/sample - loss: 0.5343 - accuracy: 0.7125 - val_loss: 0.6397 - val_accuracy: 0.5966\n",
      "Epoch 4/5\n",
      "1426/1426 [==============================] - 532s 373ms/sample - loss: 0.4612 - accuracy: 0.7784 - val_loss: 0.6127 - val_accuracy: 0.7311\n",
      "Epoch 5/5\n",
      "1426/1426 [==============================] - 550s 386ms/sample - loss: 0.3564 - accuracy: 0.8387 - val_loss: 0.7101 - val_accuracy: 0.6576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feb37f9e290>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2,2), strides=(2,2)))\n",
    "\n",
    "# flatten and make dense\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_test, y_test),\n",
    "          batch_size=64,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 254, 254, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 125, 125, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 246016)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                15745088  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 15,783,873\n",
      "Trainable params: 15,783,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score was in epoch 4 with a train accuracy of 78% and test accuracy of 73%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nnet)",
   "language": "python",
   "name": "nnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
