{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "# create list\n",
    "healthycrop_arrays = []\n",
    "# define filepath for healthy crop images\n",
    "healthycrop_path = 'Data/crop_images/healthy/'\n",
    "\n",
    "# convert each image to normalized array and store\n",
    "count = 0\n",
    "for file in os.listdir(healthycrop_path):\n",
    "    if count < 500:\n",
    "        try:\n",
    "            # target_size automatically resizes each img on import\n",
    "            healthy = load_img(healthycrop_path + file, target_size=(256, 256))\n",
    "            healthy_arr = img_to_array(healthy) / 255\n",
    "            healthycrop_arrays.append(healthy_arr)\n",
    "        except:\n",
    "            print(f'Error for file: {file}')\n",
    "        count +=1\n",
    "\n",
    "print(f'{len(healthycrop_arrays)} pictures converted.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "# create list\n",
    "healthyhouse_arrays = []\n",
    "# define filepath for healthy houseplant images\n",
    "healthyhouse_path = 'Data/houseplant_images/healthy/'\n",
    "\n",
    "# convert each image to normalized array and store\n",
    "count = 0\n",
    "for file in os.listdir(healthyhouse_path):\n",
    "    if count < 451:\n",
    "        try:\n",
    "            # target_size automatically resizes each img on import\n",
    "            healthy = load_img(healthyhouse_path + file, target_size=(256, 256))\n",
    "            healthy_arr = img_to_array(healthy) / 255\n",
    "            healthyhouse_arrays.append(healthy_arr)\n",
    "        except:\n",
    "            print(f'Error for file: {file}')\n",
    "        count +=1\n",
    "\n",
    "print(f'{len(healthyhouse_arrays)} pictures converted.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "# create list\n",
    "diseasedcrop_arrays = []\n",
    "# define filepath for diseased crop images\n",
    "diseased_path = 'Data/crop_images/diseased/'\n",
    "\n",
    "# convert each image to normalized array and store\n",
    "count = 0\n",
    "for file in os.listdir(diseased_path):\n",
    "    if count < 500:\n",
    "        try:\n",
    "            # target_size automatically resizes each img on import\n",
    "            diseased = load_img(diseased_path + file, target_size=(256, 256))\n",
    "            diseased_arr = img_to_array(diseased) / 255\n",
    "            diseasedcrop_arrays.append(diseased_arr)\n",
    "        except:\n",
    "            print(f'Error for file: {file}')\n",
    "        count +=1\n",
    "\n",
    "print(f'{len(diseasedcrop_arrays)} pictures converted.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "# create list\n",
    "wiltedhouse_arrays = []\n",
    "# define filepath for wilted houseplant images\n",
    "wilted_path = 'Data/houseplant_images/wilted/'\n",
    "\n",
    "# convert each image to normalized array and store\n",
    "count = 0\n",
    "for file in os.listdir(wilted_path):\n",
    "    if count < 451:\n",
    "        try:\n",
    "            # target_size automatically resizes each img on import\n",
    "            diseased = load_img(wilted_path + file, target_size=(256, 256))\n",
    "            diseased_arr = img_to_array(diseased) / 255\n",
    "            wiltedhouse_arrays.append(diseased_arr)\n",
    "        except:\n",
    "            print(f'Error for file: {file}')\n",
    "        count +=1\n",
    "\n",
    "print(f'{len(wiltedhouse_arrays)} pictures converted.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for file: .DS_Store\n",
      "140 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "# create list\n",
    "diseasedreddit_arrays = []\n",
    "# define filepath for wilted houseplant images\n",
    "diseasedreddit_path = 'Data/reddit/diseased/'\n",
    "\n",
    "# convert each image to normalized array and store\n",
    "count = 0\n",
    "for file in os.listdir(diseasedreddit_path):\n",
    "    if count < 141:\n",
    "        try:\n",
    "            # target_size automatically resizes each img on import\n",
    "            diseased = load_img(diseasedreddit_path + file, target_size=(256, 256))\n",
    "            diseased_arr = img_to_array(diseased) / 255\n",
    "            diseasedreddit_arrays.append(diseased_arr)\n",
    "        except:\n",
    "            print(f'Error for file: {file}')\n",
    "        count +=1\n",
    "\n",
    "print(f'{len(diseasedreddit_arrays)} pictures converted.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "# create list\n",
    "wiltedreddit_arrays = []\n",
    "# define filepath for wilted houseplant images\n",
    "wiltedreddit_path = 'Data/reddit/wilted/'\n",
    "\n",
    "# convert each image to normalized array and store\n",
    "count = 0\n",
    "for file in os.listdir(wiltedreddit_path):\n",
    "    if count < 174:\n",
    "        try:\n",
    "            # target_size automatically resizes each img on import\n",
    "            diseased = load_img(wiltedreddit_path + file, target_size=(256, 256))\n",
    "            diseased_arr = img_to_array(diseased) / 255\n",
    "            wiltedreddit_arrays.append(diseased_arr)\n",
    "        except:\n",
    "            print(f'Error for file: {file}')\n",
    "        count +=1\n",
    "\n",
    "print(f'{len(wiltedreddit_arrays)} pictures converted.')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (2216, 256, 256, 3)\n",
      "y shape: (2216,)\n"
     ]
    }
   ],
   "source": [
    "# X should contain all converted images\n",
    "X = healthycrop_arrays + healthyhouse_arrays + diseasedcrop_arrays + wiltedhouse_arrays + diseasedreddit_arrays + wiltedreddit_arrays\n",
    "# convert to array and check shape\n",
    "X_arr = np.array(X)\n",
    "print(f'X shape: {X_arr.shape}')\n",
    "\n",
    "# 0 for healthy, 1 for not healthy\n",
    "y = [0] * 951 + [1] * 951 + [1] * 314\n",
    "# convert to array and check shape\n",
    "y = np.array(y)\n",
    "print(f'y shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1662 samples, validate on 554 samples\n",
      "Epoch 1/10\n",
      "1662/1662 [==============================] - 117s 71ms/sample - loss: 0.6883 - accuracy: 0.5584 - val_loss: 0.6748 - val_accuracy: 0.5704\n",
      "Epoch 2/10\n",
      "1662/1662 [==============================] - 116s 70ms/sample - loss: 0.6323 - accuracy: 0.6492 - val_loss: 0.6239 - val_accuracy: 0.6552\n",
      "Epoch 3/10\n",
      "1662/1662 [==============================] - 116s 70ms/sample - loss: 0.5370 - accuracy: 0.7304 - val_loss: 0.4875 - val_accuracy: 0.7888\n",
      "Epoch 4/10\n",
      "1662/1662 [==============================] - 116s 70ms/sample - loss: 0.5189 - accuracy: 0.7521 - val_loss: 0.4865 - val_accuracy: 0.7870\n",
      "Epoch 5/10\n",
      "1662/1662 [==============================] - 116s 70ms/sample - loss: 0.5071 - accuracy: 0.7533 - val_loss: 0.5358 - val_accuracy: 0.7383\n",
      "Epoch 6/10\n",
      "1662/1662 [==============================] - 121s 73ms/sample - loss: 0.4809 - accuracy: 0.7828 - val_loss: 0.4989 - val_accuracy: 0.7617\n",
      "Epoch 7/10\n",
      "1662/1662 [==============================] - 117s 70ms/sample - loss: 0.4647 - accuracy: 0.7840 - val_loss: 0.4602 - val_accuracy: 0.8032\n",
      "Epoch 8/10\n",
      "1662/1662 [==============================] - 125s 75ms/sample - loss: 0.4752 - accuracy: 0.7798 - val_loss: 0.5219 - val_accuracy: 0.7274\n",
      "Epoch 9/10\n",
      "1662/1662 [==============================] - 116s 70ms/sample - loss: 0.4704 - accuracy: 0.7810 - val_loss: 0.4640 - val_accuracy: 0.7978\n",
      "Epoch 10/10\n",
      "1662/1662 [==============================] - 115s 69ms/sample - loss: 0.4325 - accuracy: 0.8045 - val_loss: 0.4523 - val_accuracy: 0.8014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fef1cd7c090>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16,(3,3), activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "model.add(Conv2D(16,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(16,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(16,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2,2), strides=(2,2)))\n",
    "\n",
    "# flatten and make dense\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16,activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_test, y_test),\n",
    "          batch_size=64,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 254, 254, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 127, 127, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 125, 125, 16)      2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 62, 62, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 60, 60, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                50192     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 57,617\n",
      "Trainable params: 57,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1662 samples, validate on 554 samples\n",
      "Epoch 1/10\n",
      "1662/1662 [==============================] - 252s 151ms/sample - loss: 0.7491 - accuracy: 0.5535 - val_loss: 0.6500 - val_accuracy: 0.5957\n",
      "Epoch 2/10\n",
      "1662/1662 [==============================] - 234s 141ms/sample - loss: 0.6040 - accuracy: 0.6649 - val_loss: 0.5693 - val_accuracy: 0.7094\n",
      "Epoch 3/10\n",
      "1662/1662 [==============================] - 236s 142ms/sample - loss: 0.5292 - accuracy: 0.7335 - val_loss: 0.5398 - val_accuracy: 0.7238\n",
      "Epoch 4/10\n",
      "1662/1662 [==============================] - 246s 148ms/sample - loss: 0.5094 - accuracy: 0.7557 - val_loss: 0.5727 - val_accuracy: 0.6968\n",
      "Epoch 5/10\n",
      "1662/1662 [==============================] - 233s 140ms/sample - loss: 0.4438 - accuracy: 0.7816 - val_loss: 0.5745 - val_accuracy: 0.7347\n",
      "Epoch 6/10\n",
      "1662/1662 [==============================] - 235s 141ms/sample - loss: 0.3630 - accuracy: 0.8442 - val_loss: 0.4873 - val_accuracy: 0.7960\n",
      "Epoch 7/10\n",
      "1662/1662 [==============================] - 243s 146ms/sample - loss: 0.3345 - accuracy: 0.8592 - val_loss: 0.6134 - val_accuracy: 0.7347\n",
      "Epoch 8/10\n",
      "1662/1662 [==============================] - 250s 150ms/sample - loss: 0.2556 - accuracy: 0.8971 - val_loss: 0.5589 - val_accuracy: 0.7798\n",
      "Epoch 9/10\n",
      "1662/1662 [==============================] - 243s 146ms/sample - loss: 0.2188 - accuracy: 0.9073 - val_loss: 0.7708 - val_accuracy: 0.7310\n",
      "Epoch 10/10\n",
      "1662/1662 [==============================] - 239s 144ms/sample - loss: 0.1337 - accuracy: 0.9537 - val_loss: 0.7591 - val_accuracy: 0.7690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fef1c55b050>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3), activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2,2), strides=(2,2)))\n",
    "\n",
    "# flatten and make dense\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32,activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_test, y_test),\n",
    "          batch_size=64,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 125, 125, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 60, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                921632    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 941,057\n",
      "Trainable params: 941,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D(pool_size= (2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size= (2,2), strides=(2,2)))\n",
    "\n",
    "# flatten and make dense\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_test, y_test),\n",
    "          batch_size=64,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train acc: 83%, test acc: 69%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nnet)",
   "language": "python",
   "name": "nnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
